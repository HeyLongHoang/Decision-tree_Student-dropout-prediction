{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {\n",
    "    'Marital status',\n",
    "    'Application mode',\n",
    "    'Application order',\n",
    "    'Course',\n",
    "    'Daytime/evening attendance\\t',\n",
    "    'Previous qualification',\n",
    "    'Previous qualification (grade)',\n",
    "    'Nacionality',\n",
    "    \"Mother's qualification\",\n",
    "    \"Father's qualification\",\n",
    "    \"Mother's occupation\",\n",
    "    \"Father's occupation\",\n",
    "    'Admission grade',\n",
    "    'Displaced',\n",
    "    'Educational special needs',\n",
    "    'Debtor',\n",
    "    'Tuition fees up to date',\n",
    "    'Gender',\n",
    "    'Scholarship holder',\n",
    "    'Age at enrollment',\n",
    "    'International',\n",
    "    'Curricular units 1st sem (credited)',\n",
    "    'Curricular units 1st sem (enrolled)',\n",
    "    'Curricular units 1st sem (evaluations)',\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (grade)',\n",
    "    'Curricular units 1st sem (without evaluations)',\n",
    "    'Curricular units 2nd sem (credited)',\n",
    "    'Curricular units 2nd sem (enrolled)',\n",
    "    'Curricular units 2nd sem (evaluations)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (grade)',\n",
    "    'Curricular units 2nd sem (without evaluations)',\n",
    "    'Unemployment rate',\n",
    "    'Inflation rate',\n",
    "    'GDP',\n",
    "}\n",
    "\n",
    "def load_student_data(path_data='data/student-dropout/data.csv'):\n",
    "    '''\n",
    "    Load dataset and remove 'Enrolled' target\n",
    "    '''\n",
    "    data = []\n",
    "    with open(path_data, encoding='utf-8-sig') as f_data:\n",
    "        for datum in csv.DictReader(f_data, delimiter=';'):\n",
    "            remove = False\n",
    "            for field in list(datum.keys()):\n",
    "                if field in fields and datum[field]:\n",
    "                    datum[field] = float(datum[field])\n",
    "                if field == 'Target':\n",
    "                    if datum[field] == 'Enrolled':\n",
    "                        remove = True\n",
    "                    elif datum[field] == 'Dropout':\n",
    "                        datum[field] = -1.\n",
    "                    else: # 'Graduated'\n",
    "                        datum[field] = 1.\n",
    "            if not remove: \n",
    "                data.append(datum)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 3630\n",
      "An example:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Marital status': 1.0,\n",
       " 'Application mode': 17.0,\n",
       " 'Application order': 3.0,\n",
       " 'Course': 9238.0,\n",
       " 'Daytime/evening attendance\\t': 1.0,\n",
       " 'Previous qualification': 1.0,\n",
       " 'Previous qualification (grade)': 131.0,\n",
       " 'Nacionality': 1.0,\n",
       " \"Mother's qualification\": 1.0,\n",
       " \"Father's qualification\": 39.0,\n",
       " \"Mother's occupation\": 5.0,\n",
       " \"Father's occupation\": 3.0,\n",
       " 'Admission grade': 122.6,\n",
       " 'Displaced': 1.0,\n",
       " 'Educational special needs': 0.0,\n",
       " 'Debtor': 0.0,\n",
       " 'Tuition fees up to date': 1.0,\n",
       " 'Gender': 0.0,\n",
       " 'Scholarship holder': 0.0,\n",
       " 'Age at enrollment': 18.0,\n",
       " 'International': 0.0,\n",
       " 'Curricular units 1st sem (credited)': 0.0,\n",
       " 'Curricular units 1st sem (enrolled)': 6.0,\n",
       " 'Curricular units 1st sem (evaluations)': 7.0,\n",
       " 'Curricular units 1st sem (approved)': 6.0,\n",
       " 'Curricular units 1st sem (grade)': 13.0,\n",
       " 'Curricular units 1st sem (without evaluations)': 0.0,\n",
       " 'Curricular units 2nd sem (credited)': 0.0,\n",
       " 'Curricular units 2nd sem (enrolled)': 6.0,\n",
       " 'Curricular units 2nd sem (evaluations)': 6.0,\n",
       " 'Curricular units 2nd sem (approved)': 6.0,\n",
       " 'Curricular units 2nd sem (grade)': 13.666666666666666,\n",
       " 'Curricular units 2nd sem (without evaluations)': 0.0,\n",
       " 'Unemployment rate': 12.4,\n",
       " 'Inflation rate': 0.5,\n",
       " 'GDP': 1.79,\n",
       " 'Target': 1.0}"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data = load_student_data()\n",
    "print('Number of examples:', len(student_data))\n",
    "print('An example:')\n",
    "student_data[100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_vals(data, f):\n",
    "    vals = [entry[f] for entry in data]\n",
    "    avg = sum(vals) / len(vals)\n",
    "    dev = [(entry[f] - avg)**2 for entry in data]\n",
    "    sd = (sum(dev) / len(vals))**0.5\n",
    "    return avg, sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard(v, std):\n",
    "    return [(v - std[0]) / std[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw(x):\n",
    "    return [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(v, entries):\n",
    "    '''\n",
    "    v -- value\n",
    "    entries -- possible values\n",
    "    '''\n",
    "    vec = len(entries) * [0]\n",
    "    vec[entries.index(v)] = 1\n",
    "    return vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    ('Marital status', one_hot),\n",
    "    ('Application mode', one_hot),\n",
    "    ('Application order', raw),\n",
    "    ('Course', one_hot),\n",
    "    ('Daytime/evening attendance\\t', raw),\n",
    "    ('Previous qualification', one_hot),\n",
    "    ('Previous qualification (grade)', standard),\n",
    "    ('Nacionality', one_hot),\n",
    "    (\"Mother's qualification\", one_hot),\n",
    "    (\"Father's qualification\", one_hot),\n",
    "    (\"Mother's occupation\", one_hot),\n",
    "    (\"Father's occupation\", one_hot),\n",
    "    ('Admission grade', standard),\n",
    "    ('Displaced', raw),\n",
    "    ('Educational special needs', raw),\n",
    "    ('Debtor', raw),\n",
    "    ('Tuition fees up to date', raw),\n",
    "    ('Gender', raw),\n",
    "    ('Scholarship holder', raw),\n",
    "    ('Age at enrollment', raw),\n",
    "    ('International', raw),\n",
    "    ('Curricular units 1st sem (credited)', raw),\n",
    "    ('Curricular units 1st sem (enrolled)', raw),\n",
    "    ('Curricular units 1st sem (evaluations)', raw),\n",
    "    ('Curricular units 1st sem (approved)', raw),\n",
    "    ('Curricular units 1st sem (grade)', raw),\n",
    "    ('Curricular units 1st sem (without evaluations)', raw),\n",
    "    ('Curricular units 2nd sem (credited)', raw),\n",
    "    ('Curricular units 2nd sem (enrolled)', raw),\n",
    "    ('Curricular units 2nd sem (evaluations)', raw),\n",
    "    ('Curricular units 2nd sem (approved)', raw),\n",
    "    ('Curricular units 2nd sem (grade)', raw),\n",
    "    ('Curricular units 2nd sem (without evaluations)', raw),\n",
    "    ('Unemployment rate', standard),\n",
    "    ('Inflation rate', standard),\n",
    "    ('GDP', standard),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, features, verbose=True):\n",
    "    features = [('Target', raw)] + features\n",
    "    std = {f : std_vals(data, f) \\\n",
    "           for (f,phi) in features if phi == standard}\n",
    "    entries = {f : list(set([entry[f] for entry in data])) \\\n",
    "               for (f, phi) in features if phi == one_hot} \n",
    "    if verbose: print('Mean and Std:', std)\n",
    "    if verbose: print('Entries in one_hot field:', entries)\n",
    "    \n",
    "    findex = 0\n",
    "    # Print the meaning of features\n",
    "    for (f, phi) in features[1:]: # skip 'Target'\n",
    "        if phi == standard:\n",
    "            if verbose: print(findex, f, 'std')\n",
    "            findex += 1\n",
    "        elif phi == one_hot:\n",
    "            for entry in entries[f]:\n",
    "                if verbose: print(findex, f, entry, 'one_hot')\n",
    "                findex += 1\n",
    "        else:\n",
    "            if verbose: print(findex, f, 'raw')\n",
    "            findex += 1\n",
    "\n",
    "    vals = []\n",
    "    for entry in data:\n",
    "        phis = []\n",
    "        for (f, phi) in features:\n",
    "            if phi == standard:\n",
    "                phis.extend(phi(entry[f], std[f]))\n",
    "            elif phi == one_hot:\n",
    "                phis.extend(phi(entry[f], entries[f]))\n",
    "            else:\n",
    "                phis.extend(phi(entry[f]))\n",
    "        vals.append(np.array([phis])) # phis of shape (1,D)\n",
    "    \n",
    "    data = np.vstack(vals)\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(data)\n",
    "    return data[:, 1:], data[:, 0:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data shape: (3630, 238)\n",
      "Labels shape: (3630, 1)\n"
     ]
    }
   ],
   "source": [
    "X, y = preprocess(student_data, features, verbose=False)\n",
    "print('\\nData shape:', X.shape)\n",
    "print('Labels shape:', y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(data, labels, test_pct=0.2, seed=None):\n",
    "    if seed and isinstance(seed, int):\n",
    "        np.random.seed(seed)\n",
    "    n, d = data.shape\n",
    "    idxs = np.random.permutation(n)\n",
    "    split_pt = int((1 - test_pct) * n)\n",
    "    train_idxs, test_idxs = idxs[:split_pt], idxs[split_pt:]\n",
    "    X_train, y_train = data[train_idxs, :], labels[train_idxs, :]\n",
    "    X_test, y_test = data[test_idxs, :], labels[test_idxs, :]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(data, labels, test_pct=0.2, seed=None):\n",
    "    if seed and isinstance(seed, int):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
    "    test_label_counts = (label_counts * test_pct).astype(int)\n",
    "    train_label_counts = label_counts - test_label_counts\n",
    "\n",
    "    train_idxs, test_idxs = [], []\n",
    "    for label, train_count, test_count in zip(unique_labels, train_label_counts, test_label_counts):\n",
    "        label_idxs = np.where(labels == label)[0] # return an array of indexes\n",
    "        permuted_idxs = np.random.permutation(label_idxs)\n",
    "        train_idxs.extend(permuted_idxs[:train_count])\n",
    "        test_idxs.extend(permuted_idxs[train_count:train_count+test_count])\n",
    "\n",
    "    X_train, y_train = data[train_idxs], labels[train_idxs]\n",
    "    X_test, y_test = data[test_idxs], labels[test_idxs]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train, X_test, y_test = random_split(X, y)\n",
    "X_train, y_train, X_test, y_test = stratified_split(X, y)\n",
    "X_train, y_train, X_val, y_val = stratified_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "       13., 16., 18.]), array([116,  17,  25,  20,  38,  97, 158,  45,  40,   2,   4,   7,   7,\n",
      "         2,   1,   1]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_test = np.hstack([X_val[:, 232].reshape(-1, 1), y_val])\n",
    "\n",
    "cnt = np.unique(my_test[:, 0], return_counts=True)\n",
    "\n",
    "\n",
    "for x in my_test:\n",
    "    if x[0] == 1 and x[1] == 1:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels:\n",
      "  -1.0 appears 910 times - 39.14%\n",
      "  1.0 appears 1415 times - 60.86%\n",
      "Test labels:\n",
      "  -1.0 appears 284 times - 39.17%\n",
      "  1.0 appears 441 times - 60.83%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def value_counts(y):\n",
    "    vals, cnts = np.unique(y, return_counts=True)\n",
    "    probs = cnts / np.sum(cnts)\n",
    "    for value, count, prob in zip(vals, cnts, probs):\n",
    "        print(f\"  {value} appears {count} times - {prob*100:.2f}%\")\n",
    "    return vals, cnts, probs\n",
    "\n",
    "print('Train labels:')\n",
    "train_vals, train_cnts, train_probs = value_counts(y_train)\n",
    "print('Test labels:')\n",
    "test_vals, test_cnts, test_probs = value_counts(y_test)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "ax1.bar(train_vals, train_probs)\n",
    "ax1.set_title(\"Training set\")\n",
    "ax1.set_xlabel(\"Unique value\")\n",
    "ax1.set_ylabel(\"Probability\")\n",
    "\n",
    "ax2.bar(test_vals, test_probs)\n",
    "ax2.set_title(\"Testing set\")\n",
    "ax2.set_xlabel(\"Unique value\")\n",
    "ax2.set_ylabel(\"Probability\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "def accuracy(y_pred, y_true):\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "\n",
    "# Calculate precision\n",
    "def precision(y_pred, y_true):\n",
    "    class_labels = np.unique(y_true)  # Get unique class labels\n",
    "    precision_scores = []\n",
    "    for label in class_labels:\n",
    "        TP = np.sum(np.logical_and(y_pred == label, y_true == label))\n",
    "        FP = np.sum(np.logical_and(y_pred == label, y_true != label))\n",
    "        precision = TP / (TP + FP)\n",
    "        precision_scores.append(precision)\n",
    "    average_precision = np.mean(precision_scores)\n",
    "    return average_precision\n",
    "\n",
    "# Calculate recall\n",
    "def recall(y_pred, y_true):\n",
    "    class_labels = np.unique(y_true)  # Get unique class labels\n",
    "    recall_scores = []\n",
    "    for label in class_labels:\n",
    "        TP = np.sum(np.logical_and(y_pred == label, y_true == label))\n",
    "        FN = np.sum(np.logical_and(y_pred != label, y_true == label))\n",
    "        recall = TP / (TP + FN)\n",
    "        recall_scores.append(recall)\n",
    "    average_recall = np.mean(recall_scores)\n",
    "    return average_recall\n",
    "\n",
    "# Calculate F1 score\n",
    "def f1(y_pred, y_true):\n",
    "    class_labels = np.unique(y_true)  # Get unique class labels\n",
    "    f1_scores = []\n",
    "    for label in class_labels:\n",
    "        TP = np.sum(np.logical_and(y_pred == label, y_true == label))\n",
    "        FP = np.sum(np.logical_and(y_pred == label, y_true != label))\n",
    "        FN = np.sum(np.logical_and(y_pred != label, y_true == label))\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        f1_scores.append(f1)\n",
    "    average_f1 = np.mean(f1_scores)\n",
    "    return average_f1\n",
    "\n",
    "# Confusion matrix\n",
    "def confusion_matrix():\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree node class\n",
    "class DTNode:\n",
    "    N_THRESHOLD = 4 # don't split if node has fewer examples than this\n",
    "    H_THRESHOLD = .01 # don't split if node has entropy less than this\n",
    "    H_REDUCTION_THRESHOLD = .001 # don't split if entropy reduction is less than this\n",
    "    MAX_DEPTH = 10\n",
    "    index = 0\n",
    "\n",
    "    def __init__(self, data=None, config=None, depth=0):\n",
    "        self.config = config\n",
    "        self.depth = depth\n",
    "        if config != None:\n",
    "            self.N_THRESHOLD = config[0]\n",
    "            self.H_THRESHOLD = config[1]\n",
    "            self.H_REDUCTION_THRESHOLD = config[2]\n",
    "            self.MAX_DEPTH = config[3]\n",
    "        \n",
    "        DTNode.index += 1\n",
    "        self.index = DTNode.index # node has unique number\n",
    "        self.data = data\n",
    "        self.prob = None\n",
    "        if data is not None:\n",
    "            self.n = float(data.shape[0]) # number of examples\n",
    "            self.indices = range(data.shape[1] - 1) # feature indices\n",
    "            self.set_h()\n",
    "\n",
    "        self.splits = {}\n",
    "\n",
    "        self.feat_id = None # feature index\n",
    "        self.thres = None # threshold\n",
    "        self.lchild = None # left child\n",
    "        self.rchild = None # right child\n",
    "        self.parent = None\n",
    "\n",
    "    # Create split on feature 'i' at value 'th'\n",
    "    # def split(self, i, th):\n",
    "    #     self.feat_id = i\n",
    "    #     self.thres = th\n",
    "    #     self.lchild = DTNode(self.data[self.data[:, i] < th], self.config, self.depth + 1)\n",
    "    #     self.rchild = DTNode(self.data[self.data[:, i] >= th], self.config, self.depth + 1)\n",
    "    #     self.splits[i].remove(th)\n",
    "\n",
    "    # Evaluate candidate split by weighted average entropy\n",
    "    def split_eval(self, i, th):\n",
    "        lc = DTNode(self.data[self.data[:, i] < th], self.config, self.depth + 1)\n",
    "        rc = DTNode(self.data[self.data[:, i] >= th], self.config, self.depth + 1)\n",
    "        pl = lc.n / self.n\n",
    "        pr = 1.0 - pl\n",
    "        avgH = pl * lc.H + pr * rc.H\n",
    "        return avgH, lc, rc\n",
    "    \n",
    "    # Entropy of class labels in this node, assumes 1, -1\n",
    "    def set_h(self):\n",
    "        b = .001\n",
    "        npos = np.sum(self.data[:,-1] == 1) # count labels 1\n",
    "        p = (npos + b) / (self.n + b + b)\n",
    "        self.prob = p\n",
    "        self.H = -p * np.log(p) - (1-p) * np.log(1-p)\n",
    "\n",
    "    def build_tree(self):\n",
    "        if self.H < self.H_THRESHOLD or self.n <= self.N_THRESHOLD:\n",
    "            return\n",
    "        # Find the best split\n",
    "        (i, th, (h, lc, rc)) = argmax([(i, th, self.split_eval(i, th)) \\\n",
    "                                            for i in self.indices \\\n",
    "                                            for th in self.get_splits(i)],\n",
    "                                        lambda x : -x[2][0]) # x = (a, b, (h, c, d))\n",
    "        \n",
    "        if (self.H - h) < self.H_REDUCTION_THRESHOLD:\n",
    "            return\n",
    "\n",
    "        # limit tree depth\n",
    "        if self.depth >= self.MAX_DEPTH:\n",
    "            return\n",
    "\n",
    "        # Recurse   \n",
    "        self.feat_id = i\n",
    "        self.thres = th\n",
    "        self.lchild = lc\n",
    "        self.rchild = rc\n",
    "        self.lchild.parent = self\n",
    "        self.rchild.parent = self\n",
    "        self.lchild.build_tree()\n",
    "        self.rchild.build_tree()\n",
    "    \n",
    "    # Sort examples and return middle points between every two consecutive samples\n",
    "    def get_splits(self, i):\n",
    "        if i not in self.splits:\n",
    "            # d = np.sort(np.unique(self.data[:,i]), axis=None)\n",
    "            # d1 = d[:-1]\n",
    "            # d2 = d[1:]\n",
    "            # self.splits[i] = (d1 + d2) / 2.0\n",
    "\n",
    "            self.splits[i] = np.sort(np.unique(self.data[:,i]), axis=None)\n",
    "        return self.splits[i]\n",
    "\n",
    "    # Classify a data point\n",
    "    def classify(self, x):\n",
    "        if self.feat_id == None: # leaf node\n",
    "            return self.prob\n",
    "        elif x[self.feat_id] < self.thres:\n",
    "            return self.lchild.classify(x) # go to left child\n",
    "        else:\n",
    "            return self.rchild.classify(x) # go to right child\n",
    "        \n",
    "    def display(self, depth=0, max_depth=3):\n",
    "        if depth > max_depth:\n",
    "            print(depth*'  ', 'Depth >', max_depth)\n",
    "        if self.feat_id is None:\n",
    "            print(depth*'  ', f\"D={depth}\", '=>', '%.2f'%self.prob, '[ n=', self.n, ']')\n",
    "            return\n",
    "        print(depth*'  ', f\"D={depth}\", 'Ft.', self.feat_id, '<', self.thres, '[ n=', self.n, ']')\n",
    "        self.lchild.display(depth+1, max_depth)\n",
    "        self.rchild.display(depth+1, max_depth)\n",
    "\n",
    "def argmax(l, f):\n",
    "    \"\"\"\n",
    "    Return the element in list l that gives highest value on f\n",
    "\n",
    "    @param l: C{List} of items\n",
    "    @param f: C{Procedure} that maps an item into a numeric score\n",
    "    @returns: the element of C{l} that has the highest score\n",
    "    \"\"\"\n",
    "    vals = [f(x) for x in l]\n",
    "    return l[vals.index(max(vals))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def fit(self, X, Y, config=None):\n",
    "        D = np.hstack([X,Y])\n",
    "        self.root = DTNode(D, config)\n",
    "        self.root.build_tree()\n",
    "    def predict(self, X):\n",
    "        pred = np.array([np.apply_along_axis(self.root.classify, 1, X)]).T - 0.5\n",
    "        pred[pred >= 0] = 1\n",
    "        pred[pred < 0] = -1\n",
    "        return pred\n",
    "    def display(self, depth=0, max_depth=3):\n",
    "        self.root.display(depth, max_depth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bagging:\n",
    "    def __init__(self, num_trees=5):\n",
    "        self.ntrees = num_trees\n",
    "        self.trees = []\n",
    "    def fit(self, X, Y, config=None):\n",
    "        for i in range(self.ntrees):\n",
    "            # perms = np.random.permutation(len(X))\n",
    "            idxs = np.random.choice(len(X), size=len(X), replace=True)\n",
    "            X_train = X[idxs, :]\n",
    "            Y_train = Y[idxs, :]\n",
    "            dt = DecisionTree()\n",
    "            dt.fit(X_train, Y_train, config)\n",
    "            self.trees.append(dt)\n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        if len(self.trees) == 0: return None\n",
    "        for dt in self.trees:\n",
    "            pred = dt.predict(X)\n",
    "            preds.append(pred)\n",
    "        preds = np.hstack(preds)\n",
    "        return np.sign(preds.mean(axis=1, keepdims=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, num_trees=5, num_features=None):\n",
    "        self.ntrees = num_trees\n",
    "        self.nfeats = num_features\n",
    "        self.trees = []\n",
    "        self.feats = []\n",
    "    \n",
    "    def fit(self, X, Y, config=None):\n",
    "        for i in range(self.ntrees):\n",
    "            idxs = np.random.choice(len(X), size=len(X), replace=True)\n",
    "            if self.nfeats is not None:\n",
    "                features = np.random.choice(X.shape[1], size=self.nfeats, replace=False)\n",
    "                X_train = X[idxs][:, features]\n",
    "                self.feats.append(features)\n",
    "            else:\n",
    "                X_train = X[idxs]\n",
    "            Y_train = Y[idxs]\n",
    "            dt = DecisionTree()\n",
    "            dt.fit(X_train, Y_train, config)\n",
    "            self.trees.append(dt)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        if len(self.trees) == 0:\n",
    "            return None\n",
    "        for i in range(len(self.trees)):\n",
    "            dt = self.trees[i]\n",
    "            if self.nfeats is not None:\n",
    "                features = self.feats[i]\n",
    "                X_test = X[:, features]\n",
    "            else:\n",
    "                X_test = X\n",
    "                \n",
    "            pred = dt.predict(X_test)\n",
    "            preds.append(pred)\n",
    "        preds = np.hstack(preds)\n",
    "        return np.sign(np.mean(preds, axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "class TreeNode(object):\n",
    "    def __init__(self, ids = None, children = [], entropy = 0, depth = 0):\n",
    "        self.ids = ids           # index of data in this node\n",
    "        self.entropy = entropy   # entropy, will fill later\n",
    "        self.depth = depth       # distance to root node\n",
    "        self.split_attribute = None # which attribute is chosen, it non-leaf\n",
    "        self.children = children # list of its child nodes\n",
    "        self.order = None       # order of values of split_attribute in children\n",
    "        self.label = None       # label of node if it is a leaf\n",
    "\n",
    "    def set_properties(self, split_attribute, order):\n",
    "        self.split_attribute = split_attribute\n",
    "        self.order = order\n",
    "\n",
    "    def set_label(self, label):\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def entropy(freq):\n",
    "    # remove prob 0 \n",
    "    freq_0 = freq[np.array(freq).nonzero()[0]]\n",
    "    prob_0 = freq_0/float(freq_0.sum())\n",
    "    return -np.sum(prob_0*np.log(prob_0))\n",
    "\n",
    "class DecisionTree(object):\n",
    "    def __init__(self, max_depth= 10, min_samples_split = 2, min_gain = 1e-4):\n",
    "        self.root = None\n",
    "        self.max_depth = max_depth \n",
    "        self.min_samples_split = min_samples_split \n",
    "        self.Ntrain = 0\n",
    "        self.min_gain = min_gain\n",
    "    \n",
    "    def fit(self, data, target, config):\n",
    "        self.Ntrain = data.count()[0]\n",
    "        self.data = data \n",
    "        self.attributes = list(data)\n",
    "        self.target = target \n",
    "        self.labels = target.unique()\n",
    "        \n",
    "        ids = range(self.Ntrain)\n",
    "        self.root = TreeNode(ids = ids, entropy = self._entropy(ids), depth = 0)\n",
    "        queue = [self.root]\n",
    "        while queue:\n",
    "            node = queue.pop()\n",
    "            if node.depth < self.max_depth or node.entropy < self.min_gain:\n",
    "                node.children = self._split(node)\n",
    "                if not node.children: #leaf node\n",
    "                    self._set_label(node)\n",
    "                queue += node.children\n",
    "            else:\n",
    "                self._set_label(node)\n",
    "                \n",
    "    def _entropy(self, ids):\n",
    "        # calculate entropy of a node with index ids\n",
    "        if len(ids) == 0: return 0\n",
    "        ids = [i+1 for i in ids] # panda series index starts from 1\n",
    "        freq = np.array(self.target[ids].value_counts())\n",
    "        return entropy(freq)\n",
    "\n",
    "    def _set_label(self, node):\n",
    "        # find label for a node if it is a leaf\n",
    "        # simply chose by major voting \n",
    "        target_ids = [i + 1 for i in node.ids]  # target is a series variable\n",
    "        node.set_label(self.target[target_ids].mode()[0]) # most frequent label\n",
    "    \n",
    "    def _split(self, node):\n",
    "        ids = node.ids \n",
    "        best_gain = 0\n",
    "        best_splits = []\n",
    "        best_attribute = None\n",
    "        order = None\n",
    "        sub_data = self.data.iloc[ids, :]\n",
    "        for i, att in enumerate(self.attributes):\n",
    "            values = self.data.iloc[ids, i].unique().tolist()\n",
    "            if len(values) == 1: continue # entropy = 0\n",
    "            splits = []\n",
    "            for val in values: \n",
    "                sub_ids = sub_data.index[sub_data[att] == val].tolist()\n",
    "                splits.append([sub_id-1 for sub_id in sub_ids])\n",
    "    \n",
    "            # don't split if a node has too small number of points\n",
    "            if min(map(len, splits)) < self.min_samples_split: continue\n",
    "\n",
    "            # information gain\n",
    "            HxS= 0\n",
    "            for split in splits:\n",
    "                HxS += len(split)*self._entropy(split)/len(ids)\n",
    "            gain = node.entropy - HxS \n",
    "            if gain < self.min_gain: continue # stop if small gain \n",
    "            if gain > best_gain:\n",
    "                best_gain = gain \n",
    "                best_splits = splits\n",
    "                best_attribute = att\n",
    "                order = values\n",
    "        node.set_properties(best_attribute, order)\n",
    "        child_nodes = [TreeNode(ids = split,\n",
    "                     entropy = self._entropy(split), depth = node.depth + 1) for split in best_splits]\n",
    "        return child_nodes\n",
    "\n",
    "    def predict(self, new_data):\n",
    "        \"\"\"\n",
    "        :param new_data: a new dataframe, each row is a datapoint\n",
    "        :return: predicted labels for each row\n",
    "        \"\"\"\n",
    "        npoints = new_data.count()[0]\n",
    "        labels = [None]*npoints\n",
    "        for n in range(npoints):\n",
    "            x = new_data.iloc[n, :] # one point \n",
    "            # start from root and recursively travel if not meet a leaf \n",
    "            node = self.root\n",
    "            while node.children: \n",
    "                node = node.children[node.order.index(x[node.split_attribute])]\n",
    "            labels[n] = node.label\n",
    "            \n",
    "        return labels\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv('weather.csv', index_col = 0, parse_dates = True)\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "    tree = DecisionTree(max_depth = 3, min_samples_split = 2)\n",
    "    tree.fit(X, y)\n",
    "    print(tree.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_class, X_train, Y_train, X_test, Y_test, max_depth=5, verbose=True, config=None, args=None):\n",
    "    if args:\n",
    "        model = model_class(*args)\n",
    "    else:\n",
    "        model = model_class()\n",
    "    model.fit(X_train, Y_train, config)\n",
    "    pred_test = model.predict(X_test)\n",
    "    acc_s = accuracy(pred_test, Y_test)\n",
    "    prec_s = precision(pred_test, Y_test)\n",
    "    rec_s = recall(pred_test, Y_test)\n",
    "    f1_s = f1(pred_test, Y_test)\n",
    "    if verbose:\n",
    "        print(f'  Accuracy  : {acc_s:.5f}')\n",
    "        print(f'  Precision : {prec_s:.5f}')\n",
    "        print(f'  Recall    : {rec_s:.5f}')\n",
    "        print(f'  F1        : {f1_s:.5f}')\n",
    "        if isinstance(model, DecisionTree): \n",
    "            model.display(max_depth=max_depth)\n",
    "    \n",
    "\n",
    "    return acc_s, prec_s, rec_s, f1_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy  : 0.85000\n",
      "  Precision : 0.84473\n",
      "  Recall    : 0.83825\n",
      "  F1        : 0.84114\n",
      " D=0 Ft. 30 < 4.0 [ n= 2325.0 ]\n",
      "   D=1 Ft. 22 < 1.0 [ n= 748.0 ]\n",
      "     D=2 Ft. 12 < 141.0 [ n= 93.0 ]\n",
      "       D=3 Ft. 16 < 1.0 [ n= 56.0 ]\n",
      "         D=4 => 0.00 [ n= 9.0 ]\n",
      "         D=4 Ft. 33 < 13.9 [ n= 47.0 ]\n",
      "           D=5 Ft. 5 < 2.0 [ n= 32.0 ]\n",
      "             D=6 Ft. 15 < 1.0 [ n= 29.0 ]\n",
      "               D=7 Ft. 35 < 2.02 [ n= 27.0 ]\n",
      "                 D=8 Ft. 11 < 5.0 [ n= 25.0 ]\n",
      "                   D=9 Ft. 11 < 4.0 [ n= 8.0 ]\n",
      "                     D=10 Ft. 8 < 37.0 [ n= 5.0 ]\n",
      "                       D=11 => 1.00 [ n= 4.0 ]\n",
      "                       D=11 => 0.00 [ n= 1.0 ]\n",
      "                     D=10 => 0.00 [ n= 3.0 ]\n",
      "                   D=9 Ft. 6 < 136.0 [ n= 17.0 ]\n",
      "                     D=10 => 1.00 [ n= 10.0 ]\n",
      "                     D=10 Ft. 6 < 139.0 [ n= 7.0 ]\n",
      "                       D=11 => 0.33 [ n= 3.0 ]\n",
      "                       D=11 => 1.00 [ n= 4.0 ]\n",
      "                 D=8 => 0.00 [ n= 2.0 ]\n",
      "               D=7 => 0.00 [ n= 2.0 ]\n",
      "             D=6 => 0.00 [ n= 3.0 ]\n",
      "           D=5 Ft. 12 < 136.8 [ n= 15.0 ]\n",
      "             D=6 => 0.00 [ n= 13.0 ]\n",
      "             D=6 => 1.00 [ n= 2.0 ]\n",
      "       D=3 Ft. 6 < 159.0 [ n= 37.0 ]\n",
      "         D=4 Ft. 33 < 15.5 [ n= 23.0 ]\n",
      "           D=5 Ft. 6 < 131.0 [ n= 20.0 ]\n",
      "             D=6 => 0.00 [ n= 1.0 ]\n",
      "             D=6 => 1.00 [ n= 19.0 ]\n",
      "           D=5 => 0.33 [ n= 3.0 ]\n",
      "         D=4 Ft. 8 < 19.0 [ n= 14.0 ]\n",
      "           D=5 Ft. 13 < 1.0 [ n= 7.0 ]\n",
      "             D=6 => 1.00 [ n= 1.0 ]\n",
      "             D=6 => 0.00 [ n= 6.0 ]\n",
      "           D=5 Ft. 12 < 143.1 [ n= 7.0 ]\n",
      "             D=6 => 0.00 [ n= 1.0 ]\n",
      "             D=6 => 1.00 [ n= 6.0 ]\n",
      "     D=2 Ft. 30 < 2.0 [ n= 655.0 ]\n",
      "       D=3 => 0.00 [ n= 487.0 ]\n",
      "       D=3 Ft. 24 < 5.0 [ n= 168.0 ]\n",
      "         D=4 Ft. 17 < 1.0 [ n= 126.0 ]\n",
      "           D=5 Ft. 22 < 6.0 [ n= 54.0 ]\n",
      "             D=6 Ft. 24 < 3.0 [ n= 23.0 ]\n",
      "               D=7 => 0.00 [ n= 7.0 ]\n",
      "               D=7 Ft. 8 < 3.0 [ n= 16.0 ]\n",
      "                 D=8 => 1.00 [ n= 4.0 ]\n",
      "                 D=8 Ft. 29 < 10.0 [ n= 12.0 ]\n",
      "                   D=9 => 0.00 [ n= 7.0 ]\n",
      "                   D=9 Ft. 10 < 5.0 [ n= 5.0 ]\n",
      "                     D=10 => 0.00 [ n= 2.0 ]\n",
      "                     D=10 => 1.00 [ n= 3.0 ]\n",
      "             D=6 Ft. 6 < 146.0 [ n= 31.0 ]\n",
      "               D=7 => 0.00 [ n= 30.0 ]\n",
      "               D=7 => 1.00 [ n= 1.0 ]\n",
      "           D=5 => 0.00 [ n= 72.0 ]\n",
      "         D=4 Ft. 16 < 1.0 [ n= 42.0 ]\n",
      "           D=5 => 0.00 [ n= 12.0 ]\n",
      "           D=5 Ft. 22 < 7.0 [ n= 30.0 ]\n",
      "             D=6 Ft. 6 < 132.0 [ n= 25.0 ]\n",
      "               D=7 Ft. 9 < 37.0 [ n= 12.0 ]\n",
      "                 D=8 => 1.00 [ n= 8.0 ]\n",
      "                 D=8 => 0.50 [ n= 4.0 ]\n",
      "               D=7 Ft. 10 < 5.0 [ n= 13.0 ]\n",
      "                 D=8 Ft. 11 < 7.0 [ n= 6.0 ]\n",
      "                   D=9 => 1.00 [ n= 4.0 ]\n",
      "                   D=9 => 0.00 [ n= 2.0 ]\n",
      "                 D=8 => 0.00 [ n= 7.0 ]\n",
      "             D=6 => 0.00 [ n= 5.0 ]\n",
      "   D=1 Ft. 16 < 1.0 [ n= 1577.0 ]\n",
      "     D=2 Ft. 30 < 6.0 [ n= 79.0 ]\n",
      "       D=3 Ft. 7 < 24.0 [ n= 49.0 ]\n",
      "         D=4 Ft. 18 < 1.0 [ n= 47.0 ]\n",
      "           D=5 => 0.00 [ n= 45.0 ]\n",
      "           D=5 => 0.50 [ n= 2.0 ]\n",
      "         D=4 => 1.00 [ n= 2.0 ]\n",
      "       D=3 Ft. 22 < 7.0 [ n= 30.0 ]\n",
      "         D=4 Ft. 31 < 12.166666666666666 [ n= 15.0 ]\n",
      "           D=5 => 0.00 [ n= 2.0 ]\n",
      "           D=5 Ft. 35 < 1.79 [ n= 13.0 ]\n",
      "             D=6 => 1.00 [ n= 9.0 ]\n",
      "             D=6 => 0.50 [ n= 4.0 ]\n",
      "         D=4 Ft. 1 < 51.0 [ n= 15.0 ]\n",
      "           D=5 => 0.00 [ n= 12.0 ]\n",
      "           D=5 => 0.67 [ n= 3.0 ]\n",
      "     D=2 Ft. 30 < 6.0 [ n= 1498.0 ]\n",
      "       D=3 Ft. 28 < 7.0 [ n= 473.0 ]\n",
      "         D=4 Ft. 3 < 9254.0 [ n= 445.0 ]\n",
      "           D=5 Ft. 5 < 6.0 [ n= 248.0 ]\n",
      "             D=6 Ft. 31 < 11.2 [ n= 229.0 ]\n",
      "               D=7 Ft. 24 < 5.0 [ n= 25.0 ]\n",
      "                 D=8 Ft. 29 < 9.0 [ n= 13.0 ]\n",
      "                   D=9 => 1.00 [ n= 3.0 ]\n",
      "                   D=9 Ft. 17 < 1.0 [ n= 10.0 ]\n",
      "                     D=10 Ft. 8 < 37.0 [ n= 7.0 ]\n",
      "                       D=11 => 1.00 [ n= 3.0 ]\n",
      "                       D=11 => 0.25 [ n= 4.0 ]\n",
      "                     D=10 => 0.00 [ n= 3.0 ]\n",
      "                 D=8 => 1.00 [ n= 12.0 ]\n",
      "               D=7 Ft. 25 < 13.666666666666666 [ n= 204.0 ]\n",
      "                 D=8 Ft. 12 < 132.1 [ n= 160.0 ]\n",
      "                   D=9 => 1.00 [ n= 116.0 ]\n",
      "                   D=9 Ft. 12 < 132.2 [ n= 44.0 ]\n",
      "                     D=10 => 0.00 [ n= 1.0 ]\n",
      "                     D=10 Ft. 19 < 40.0 [ n= 43.0 ]\n",
      "                       D=11 Ft. 35 < -0.92 [ n= 41.0 ]\n",
      "                         D=12 Ft. 8 < 19.0 [ n= 12.0 ]\n",
      "                           D=13 => 0.33 [ n= 3.0 ]\n",
      "                           D=13 => 1.00 [ n= 9.0 ]\n",
      "                         D=12 => 1.00 [ n= 29.0 ]\n",
      "                       D=11 => 0.50 [ n= 2.0 ]\n",
      "                 D=8 Ft. 10 < 7.0 [ n= 44.0 ]\n",
      "                   D=9 Ft. 1 < 5.0 [ n= 23.0 ]\n",
      "                     D=10 Ft. 23 < 15.0 [ n= 14.0 ]\n",
      "                       D=11 => 1.00 [ n= 13.0 ]\n",
      "                       D=11 => 0.00 [ n= 1.0 ]\n",
      "                     D=10 Ft. 31 < 14.571428571428571 [ n= 9.0 ]\n",
      "                       D=11 Ft. 1 < 10.0 [ n= 6.0 ]\n",
      "                         D=12 => 0.00 [ n= 1.0 ]\n",
      "                         D=12 Ft. 23 < 10.0 [ n= 5.0 ]\n",
      "                           D=13 => 1.00 [ n= 4.0 ]\n",
      "                           D=13 => 0.00 [ n= 1.0 ]\n",
      "                       D=11 => 0.00 [ n= 3.0 ]\n",
      "                   D=9 => 1.00 [ n= 21.0 ]\n",
      "             D=6 Ft. 18 < 1.0 [ n= 19.0 ]\n",
      "               D=7 Ft. 10 < 4.0 [ n= 14.0 ]\n",
      "                 D=8 => 1.00 [ n= 4.0 ]\n",
      "                 D=8 Ft. 29 < 7.0 [ n= 10.0 ]\n",
      "                   D=9 => 1.00 [ n= 2.0 ]\n",
      "                   D=9 Ft. 6 < 160.0 [ n= 8.0 ]\n",
      "                     D=10 => 0.00 [ n= 7.0 ]\n",
      "                     D=10 => 1.00 [ n= 1.0 ]\n",
      "               D=7 => 1.00 [ n= 5.0 ]\n",
      "           D=5 Ft. 24 < 4.0 [ n= 197.0 ]\n",
      "             D=6 Ft. 31 < 13.25 [ n= 14.0 ]\n",
      "               D=7 => 0.00 [ n= 11.0 ]\n",
      "               D=7 => 0.67 [ n= 3.0 ]\n",
      "             D=6 Ft. 31 < 10.6 [ n= 183.0 ]\n",
      "               D=7 Ft. 2 < 2.0 [ n= 7.0 ]\n",
      "                 D=8 => 1.00 [ n= 1.0 ]\n",
      "                 D=8 => 0.00 [ n= 6.0 ]\n",
      "               D=7 Ft. 12 < 113.2 [ n= 176.0 ]\n",
      "                 D=8 => 1.00 [ n= 26.0 ]\n",
      "                 D=8 Ft. 31 < 11.8 [ n= 150.0 ]\n",
      "                   D=9 Ft. 35 < -1.7 [ n= 28.0 ]\n",
      "                     D=10 Ft. 9 < 3.0 [ n= 11.0 ]\n",
      "                       D=11 => 0.33 [ n= 3.0 ]\n",
      "                       D=11 => 1.00 [ n= 8.0 ]\n",
      "                     D=10 Ft. 23 < 10.0 [ n= 17.0 ]\n",
      "                       D=11 Ft. 3 < 9853.0 [ n= 12.0 ]\n",
      "                         D=12 => 1.00 [ n= 4.0 ]\n",
      "                         D=12 Ft. 6 < 160.0 [ n= 8.0 ]\n",
      "                           D=13 => 0.00 [ n= 6.0 ]\n",
      "                           D=13 => 1.00 [ n= 2.0 ]\n",
      "                       D=11 => 0.00 [ n= 5.0 ]\n",
      "                   D=9 Ft. 3 < 9670.0 [ n= 122.0 ]\n",
      "                     D=10 Ft. 19 < 54.0 [ n= 20.0 ]\n",
      "                       D=11 => 1.00 [ n= 19.0 ]\n",
      "                       D=11 => 0.00 [ n= 1.0 ]\n",
      "                     D=10 Ft. 31 < 13.8 [ n= 102.0 ]\n",
      "                       D=11 Ft. 1 < 43.0 [ n= 69.0 ]\n",
      "                         D=12 Ft. 18 < 1.0 [ n= 64.0 ]\n",
      "                           D=13 Ft. 3 < 9773.0 [ n= 42.0 ]\n",
      "                             D=14 Ft. 8 < 37.0 [ n= 13.0 ]\n",
      "                               D=15 Ft. 2 < 2.0 [ n= 11.0 ]\n",
      "                                 D=16 Ft. 1 < 17.0 [ n= 6.0 ]\n",
      "                                   D=17 => 0.25 [ n= 4.0 ]\n",
      "                                   D=17 => 1.00 [ n= 2.0 ]\n",
      "                                 D=16 => 1.00 [ n= 5.0 ]\n",
      "                               D=15 => 0.00 [ n= 2.0 ]\n",
      "                             D=14 Ft. 11 < 5.0 [ n= 29.0 ]\n",
      "                               D=15 Ft. 12 < 131.5 [ n= 7.0 ]\n",
      "                                 D=16 => 1.00 [ n= 4.0 ]\n",
      "                                 D=16 => 0.33 [ n= 3.0 ]\n",
      "                               D=15 => 1.00 [ n= 22.0 ]\n",
      "                           D=13 Ft. 2 < 2.0 [ n= 22.0 ]\n",
      "                             D=14 Ft. 19 < 37.0 [ n= 10.0 ]\n",
      "                               D=15 => 1.00 [ n= 9.0 ]\n",
      "                               D=15 => 0.00 [ n= 1.0 ]\n",
      "                             D=14 Ft. 19 < 20.0 [ n= 12.0 ]\n",
      "                               D=15 Ft. 35 < 2.02 [ n= 10.0 ]\n",
      "                                 D=16 => 0.00 [ n= 8.0 ]\n",
      "                                 D=16 => 1.00 [ n= 2.0 ]\n",
      "                               D=15 => 1.00 [ n= 2.0 ]\n",
      "                         D=12 Ft. 3 < 9991.0 [ n= 5.0 ]\n",
      "                           D=13 => 0.00 [ n= 4.0 ]\n",
      "                           D=13 => 1.00 [ n= 1.0 ]\n",
      "                       D=11 Ft. 10 < 3.0 [ n= 33.0 ]\n",
      "                         D=12 => 0.33 [ n= 3.0 ]\n",
      "                         D=12 Ft. 23 < 12.0 [ n= 30.0 ]\n",
      "                           D=13 => 1.00 [ n= 29.0 ]\n",
      "                           D=13 => 0.00 [ n= 1.0 ]\n",
      "         D=4 Ft. 24 < 6.0 [ n= 28.0 ]\n",
      "           D=5 => 0.00 [ n= 15.0 ]\n",
      "           D=5 Ft. 34 < 1.4 [ n= 13.0 ]\n",
      "             D=6 => 0.00 [ n= 6.0 ]\n",
      "             D=6 Ft. 5 < 12.0 [ n= 7.0 ]\n",
      "               D=7 => 1.00 [ n= 6.0 ]\n",
      "               D=7 => 0.00 [ n= 1.0 ]\n",
      "       D=3 Ft. 29 < 9.0 [ n= 1025.0 ]\n",
      "         D=4 Ft. 26 < 1.0 [ n= 668.0 ]\n",
      "           D=5 Ft. 3 < 9556.0 [ n= 656.0 ]\n",
      "             D=6 Ft. 31 < 16.666666666666668 [ n= 498.0 ]\n",
      "               D=7 Ft. 33 < 13.9 [ n= 495.0 ]\n",
      "                 D=8 => 1.00 [ n= 391.0 ]\n",
      "                 D=8 Ft. 2 < 2.0 [ n= 104.0 ]\n",
      "                   D=9 => 1.00 [ n= 75.0 ]\n",
      "                   D=9 Ft. 11 < 9.0 [ n= 29.0 ]\n",
      "                     D=10 Ft. 8 < 3.0 [ n= 28.0 ]\n",
      "                       D=11 Ft. 12 < 132.6 [ n= 8.0 ]\n",
      "                         D=12 => 0.50 [ n= 4.0 ]\n",
      "                         D=12 => 1.00 [ n= 4.0 ]\n",
      "                       D=11 => 1.00 [ n= 20.0 ]\n",
      "                     D=10 => 0.00 [ n= 1.0 ]\n",
      "               D=7 => 0.33 [ n= 3.0 ]\n",
      "             D=6 Ft. 31 < 11.857142857142858 [ n= 158.0 ]\n",
      "               D=7 Ft. 1 < 18.0 [ n= 7.0 ]\n",
      "                 D=8 => 0.75 [ n= 4.0 ]\n",
      "                 D=8 => 0.00 [ n= 3.0 ]\n",
      "               D=7 Ft. 13 < 1.0 [ n= 151.0 ]\n",
      "                 D=8 => 1.00 [ n= 54.0 ]\n",
      "                 D=8 Ft. 31 < 14.0625 [ n= 97.0 ]\n",
      "                   D=9 Ft. 6 < 126.0 [ n= 65.0 ]\n",
      "                     D=10 => 1.00 [ n= 18.0 ]\n",
      "                     D=10 Ft. 10 < 8.0 [ n= 47.0 ]\n",
      "                       D=11 Ft. 23 < 10.0 [ n= 25.0 ]\n",
      "                         D=12 Ft. 31 < 13.857142857142858 [ n= 24.0 ]\n",
      "                           D=13 => 1.00 [ n= 23.0 ]\n",
      "                           D=13 => 0.00 [ n= 1.0 ]\n",
      "                         D=12 => 0.00 [ n= 1.0 ]\n",
      "                       D=11 Ft. 6 < 143.0 [ n= 22.0 ]\n",
      "                         D=12 Ft. 6 < 135.0 [ n= 20.0 ]\n",
      "                           D=13 Ft. 3 < 9773.0 [ n= 12.0 ]\n",
      "                             D=14 => 0.00 [ n= 2.0 ]\n",
      "                             D=14 Ft. 9 < 19.0 [ n= 10.0 ]\n",
      "                               D=15 => 0.00 [ n= 2.0 ]\n",
      "                               D=15 Ft. 6 < 134.0 [ n= 8.0 ]\n",
      "                                 D=16 => 1.00 [ n= 7.0 ]\n",
      "                                 D=16 => 0.00 [ n= 1.0 ]\n",
      "                           D=13 => 1.00 [ n= 8.0 ]\n",
      "                         D=12 => 0.00 [ n= 2.0 ]\n",
      "                   D=9 => 1.00 [ n= 32.0 ]\n",
      "           D=5 Ft. 6 < 131.0 [ n= 12.0 ]\n",
      "             D=6 Ft. 31 < 12.625 [ n= 7.0 ]\n",
      "               D=7 => 0.00 [ n= 4.0 ]\n",
      "               D=7 => 0.67 [ n= 3.0 ]\n",
      "             D=6 => 1.00 [ n= 5.0 ]\n",
      "         D=4 Ft. 25 < 11.68 [ n= 357.0 ]\n",
      "           D=5 Ft. 25 < 11.357142857142858 [ n= 51.0 ]\n",
      "             D=6 Ft. 32 < 1.0 [ n= 25.0 ]\n",
      "               D=7 Ft. 12 < 111.1 [ n= 23.0 ]\n",
      "                 D=8 => 0.50 [ n= 2.0 ]\n",
      "                 D=8 => 1.00 [ n= 21.0 ]\n",
      "               D=7 => 0.00 [ n= 2.0 ]\n",
      "             D=6 Ft. 6 < 136.0 [ n= 26.0 ]\n",
      "               D=7 Ft. 24 < 17.0 [ n= 21.0 ]\n",
      "                 D=8 Ft. 6 < 128.0 [ n= 17.0 ]\n",
      "                   D=9 => 0.00 [ n= 9.0 ]\n",
      "                   D=9 Ft. 3 < 9500.0 [ n= 8.0 ]\n",
      "                     D=10 Ft. 1 < 53.0 [ n= 5.0 ]\n",
      "                       D=11 => 0.00 [ n= 4.0 ]\n",
      "                       D=11 => 1.00 [ n= 1.0 ]\n",
      "                     D=10 => 1.00 [ n= 3.0 ]\n",
      "                 D=8 => 1.00 [ n= 4.0 ]\n",
      "               D=7 => 1.00 [ n= 5.0 ]\n",
      "           D=5 Ft. 31 < 11.166666666666666 [ n= 306.0 ]\n",
      "             D=6 Ft. 33 < 12.7 [ n= 9.0 ]\n",
      "               D=7 => 1.00 [ n= 5.0 ]\n",
      "               D=7 => 0.00 [ n= 4.0 ]\n",
      "             D=6 Ft. 12 < 118.4 [ n= 297.0 ]\n",
      "               D=7 Ft. 34 < -0.3 [ n= 56.0 ]\n",
      "                 D=8 Ft. 3 < 9670.0 [ n= 5.0 ]\n",
      "                   D=9 => 1.00 [ n= 4.0 ]\n",
      "                   D=9 => 0.00 [ n= 1.0 ]\n",
      "                 D=8 => 1.00 [ n= 51.0 ]\n",
      "               D=7 Ft. 24 < 6.0 [ n= 241.0 ]\n",
      "                 D=8 Ft. 9 < 37.0 [ n= 8.0 ]\n",
      "                   D=9 Ft. 34 < 2.8 [ n= 5.0 ]\n",
      "                     D=10 => 0.00 [ n= 4.0 ]\n",
      "                     D=10 => 1.00 [ n= 1.0 ]\n",
      "                   D=9 => 1.00 [ n= 3.0 ]\n",
      "                 D=8 Ft. 2 < 2.0 [ n= 233.0 ]\n",
      "                   D=9 Ft. 18 < 1.0 [ n= 157.0 ]\n",
      "                     D=10 Ft. 19 < 53.0 [ n= 108.0 ]\n",
      "                       D=11 Ft. 8 < 4.0 [ n= 107.0 ]\n",
      "                         D=12 Ft. 34 < 0.6 [ n= 50.0 ]\n",
      "                           D=13 Ft. 10 < 9.0 [ n= 28.0 ]\n",
      "                             D=14 => 1.00 [ n= 24.0 ]\n",
      "                             D=14 => 0.75 [ n= 4.0 ]\n",
      "                           D=13 Ft. 30 < 11.0 [ n= 22.0 ]\n",
      "                             D=14 Ft. 3 < 9085.0 [ n= 14.0 ]\n",
      "                               D=15 => 0.00 [ n= 3.0 ]\n",
      "                               D=15 Ft. 17 < 1.0 [ n= 11.0 ]\n",
      "                                 D=16 => 1.00 [ n= 7.0 ]\n",
      "                                 D=16 => 0.50 [ n= 4.0 ]\n",
      "                             D=14 => 1.00 [ n= 8.0 ]\n",
      "                         D=12 Ft. 29 < 22.0 [ n= 57.0 ]\n",
      "                           D=13 => 1.00 [ n= 55.0 ]\n",
      "                           D=13 => 0.50 [ n= 2.0 ]\n",
      "                       D=11 => 0.00 [ n= 1.0 ]\n",
      "                     D=10 => 1.00 [ n= 49.0 ]\n",
      "                   D=9 Ft. 23 < 11.0 [ n= 76.0 ]\n",
      "                     D=10 Ft. 25 < 14.20857142857143 [ n= 60.0 ]\n",
      "                       D=11 Ft. 6 < 132.0 [ n= 47.0 ]\n",
      "                         D=12 Ft. 31 < 13.085714285714284 [ n= 10.0 ]\n",
      "                           D=13 => 0.00 [ n= 3.0 ]\n",
      "                           D=13 Ft. 31 < 13.744444444444444 [ n= 7.0 ]\n",
      "                             D=14 => 1.00 [ n= 4.0 ]\n",
      "                             D=14 => 0.00 [ n= 3.0 ]\n",
      "                         D=12 Ft. 31 < 15.622222222222222 [ n= 37.0 ]\n",
      "                           D=13 Ft. 10 < 7.0 [ n= 35.0 ]\n",
      "                             D=14 Ft. 2 < 3.0 [ n= 19.0 ]\n",
      "                               D=15 => 1.00 [ n= 6.0 ]\n",
      "                               D=15 Ft. 33 < 11.1 [ n= 13.0 ]\n",
      "                                 D=16 => 1.00 [ n= 4.0 ]\n",
      "                                 D=16 Ft. 25 < 13.44285714285714 [ n= 9.0 ]\n",
      "                                   D=17 => 0.00 [ n= 4.0 ]\n",
      "                                   D=17 Ft. 31 < 14.75 [ n= 5.0 ]\n",
      "                                     D=18 => 1.00 [ n= 4.0 ]\n",
      "                                     D=18 => 0.00 [ n= 1.0 ]\n",
      "                             D=14 => 1.00 [ n= 16.0 ]\n",
      "                           D=13 => 0.00 [ n= 2.0 ]\n",
      "                       D=11 => 1.00 [ n= 13.0 ]\n",
      "                     D=10 => 1.00 [ n= 16.0 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.85, 0.8447293447293447, 0.8382461219752655, 0.8411364130075465)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(DecisionTree, X_train, y_train, X_val, y_val, max_depth=20, verbose=True, config=(4, 0.01, 0.001, 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "  Accuracy  : 0.84731\n",
      "  Precision : 0.83872\n",
      "  Recall    : 0.83645\n",
      "  F1        : 0.83755\n",
      "Round 2\n",
      "  Accuracy  : 0.87527\n",
      "  Precision : 0.88299\n",
      "  Recall    : 0.86288\n",
      "  F1        : 0.86935\n",
      "Round 3\n",
      "  Accuracy  : 0.82151\n",
      "  Precision : 0.83266\n",
      "  Recall    : 0.78889\n",
      "  F1        : 0.80077\n",
      "Round 4\n",
      "  Accuracy  : 0.88817\n",
      "  Precision : 0.90345\n",
      "  Recall    : 0.86796\n",
      "  F1        : 0.87916\n",
      "Round 5\n",
      "  Accuracy  : 0.88172\n",
      "  Precision : 0.88561\n",
      "  Recall    : 0.85632\n",
      "  F1        : 0.86757\n",
      "\n",
      "CROSS VALIDATION RESULTS:\n",
      "- Avg. Accuracy  : 0.86280\n",
      "- Avg. Precision : 0.86869\n",
      "- Avg. Recall    : 0.84250\n",
      "- Avg. F1        : 0.85088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8627956989247311, 0.868685735387395, 0.842500525099822, 0.8508793497571474)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_validate(data, labels, k=10, model='DecisionTree', verbose=True, config=None, args=None):\n",
    "    if model == 'Bagging':\n",
    "        model_class = Bagging\n",
    "    elif model == 'RandomForest':\n",
    "        model_class = RandomForest\n",
    "    else:\n",
    "        model_class = DecisionTree\n",
    "    indices = np.random.permutation(data.shape[0])\n",
    "    X = data[indices,:]\n",
    "    Y = labels[indices,:]\n",
    "    s_data = np.array_split(X, k, axis=0)\n",
    "    s_labels = np.array_split(Y, k, axis=0)\n",
    "    acc_s = 0.\n",
    "    prec_s = 0.\n",
    "    rec_s = 0.\n",
    "    f1_s = 0.\n",
    "    for i in range(k):\n",
    "        X_train = np.concatenate(s_data[:i] + s_data[i+1:], axis=0)\n",
    "        Y_train = np.concatenate(s_labels[:i] + s_labels[i+1:], axis=0)\n",
    "        X_test = np.array(s_data[i])\n",
    "        Y_test = np.array(s_labels[i])\n",
    "        if verbose == \"first_tree\":\n",
    "            if i == 0:\n",
    "                acc, prec, rec, f1 = evaluate(model_class, X_train, Y_train, X_test, Y_test, verbose=True, config=config, args=args)\n",
    "            else:\n",
    "                acc, prec, rec, f1 = evaluate(model_class, X_train, Y_train, X_test, Y_test, verbose=False, config=config, args=args)\n",
    "        elif verbose == True:\n",
    "            print('Round',i+1)\n",
    "            acc, prec, rec, f1 = evaluate(model_class, X_train, Y_train, X_test, Y_test, verbose=True, config=config, args=args)\n",
    "        else:\n",
    "            acc, prec, rec, f1 = evaluate(model_class, X_train, Y_train, X_test, Y_test, verbose=False, config=config, args=args)\n",
    "        acc_s += acc\n",
    "        prec_s += prec\n",
    "        rec_s += rec\n",
    "        f1_s += f1\n",
    "    print('\\nCROSS VALIDATION RESULTS:')\n",
    "    print(f'- Avg. Accuracy  : {acc_s/k:.5f}')\n",
    "    print(f'- Avg. Precision : {prec_s/k:.5f}')\n",
    "    print(f'- Avg. Recall    : {rec_s/k:.5f}')\n",
    "    print(f'- Avg. F1        : {f1_s/k:.5f}')\n",
    "    return acc_s/k, prec_s/k, rec_s/k, f1_s/k\n",
    "\n",
    "\n",
    "cross_validate(X_train, y_train, model='RandomForest', k=5, verbose=True, args=[5, 150],config=(4, 0.01, 0.001, 1))\n",
    "# cross_validate(X_train, y_train, model='RandomForest', k=5, verbose=True, args=[7], config=(4, 0.01, 0.001, 1))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO (Viet)\n",
    "1. Find the best values \n",
    "    of N_THRESHOLD, H_THRESHOLD, H_REDUCTION_THRESHOLD for Decision tree\n",
    "2. Find the best values\n",
    "    of 'num_trees' and 'num_features' for Random forest\n",
    "3. Find the best values\n",
    "    of 'num_trees' for Bagging\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO\n",
    "- Function to turn user inputs into vector ready to be put into 'predit' function (shape (1, 238)) (Lam)\n",
    "- Plot various values of hyperparams for dtree, bagging, rforest -> find optimal values & Confusion matrix (Loc)\n",
    "- Fix errors for functions to save and load models (by yaml) (Dai)\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warnings:** Don't run this part until very end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(RandomForest, X_train, y_train, X_test, y_test, args=[5, 150])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForest(num_trees=5, num_features=150)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 123\n",
    "\n",
    "# load model\n",
    "\n",
    "print('(Graduated: 1.0, Dropout: -1.0)')\n",
    "print('- Prediction :', rf_clf.predict(X_test[id,:].reshape(1,-1))[0][0])\n",
    "print('- Actual     :', y_test[id][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
