{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {\n",
    "    'Marital status',\n",
    "    'Application mode',\n",
    "    'Application order',\n",
    "    'Course',\n",
    "    'Daytime/evening attendance\\t',\n",
    "    'Previous qualification',\n",
    "    'Previous qualification (grade)',\n",
    "    'Nacionality',\n",
    "    \"Mother's qualification\",\n",
    "    \"Father's qualification\",\n",
    "    \"Mother's occupation\",\n",
    "    \"Father's occupation\",\n",
    "    'Admission grade',\n",
    "    'Displaced',\n",
    "    'Educational special needs',\n",
    "    'Debtor',\n",
    "    'Tuition fees up to date',\n",
    "    'Gender',\n",
    "    'Scholarship holder',\n",
    "    'Age at enrollment',\n",
    "    'International',\n",
    "    'Curricular units 1st sem (credited)',\n",
    "    'Curricular units 1st sem (enrolled)',\n",
    "    'Curricular units 1st sem (evaluations)',\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (grade)',\n",
    "    'Curricular units 1st sem (without evaluations)',\n",
    "    'Curricular units 2nd sem (credited)',\n",
    "    'Curricular units 2nd sem (enrolled)',\n",
    "    'Curricular units 2nd sem (evaluations)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (grade)',\n",
    "    'Curricular units 2nd sem (without evaluations)',\n",
    "    'Unemployment rate',\n",
    "    'Inflation rate',\n",
    "    'GDP',\n",
    "}\n",
    "\n",
    "def load_student_data(path_data='data/student-dropout/data.csv'):\n",
    "    '''\n",
    "    Load dataset and remove 'Enrolled' target\n",
    "    '''\n",
    "    data = []\n",
    "    with open(path_data, encoding='utf-8-sig') as f_data:\n",
    "        for datum in csv.DictReader(f_data, delimiter=';'):\n",
    "            remove = False\n",
    "            for field in list(datum.keys()):\n",
    "                if field in fields and datum[field]:\n",
    "                    datum[field] = float(datum[field])\n",
    "                if field == 'Target':\n",
    "                    if datum[field] == 'Enrolled':\n",
    "                        remove = True\n",
    "                    elif datum[field] == 'Dropout':\n",
    "                        datum[field] = -1.\n",
    "                    else: # 'Graduated'\n",
    "                        datum[field] = 1.\n",
    "            if not remove: \n",
    "                data.append(datum)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 3630\n",
      "An example:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Marital status': 1.0,\n",
       " 'Application mode': 17.0,\n",
       " 'Application order': 3.0,\n",
       " 'Course': 9238.0,\n",
       " 'Daytime/evening attendance\\t': 1.0,\n",
       " 'Previous qualification': 1.0,\n",
       " 'Previous qualification (grade)': 131.0,\n",
       " 'Nacionality': 1.0,\n",
       " \"Mother's qualification\": 1.0,\n",
       " \"Father's qualification\": 39.0,\n",
       " \"Mother's occupation\": 5.0,\n",
       " \"Father's occupation\": 3.0,\n",
       " 'Admission grade': 122.6,\n",
       " 'Displaced': 1.0,\n",
       " 'Educational special needs': 0.0,\n",
       " 'Debtor': 0.0,\n",
       " 'Tuition fees up to date': 1.0,\n",
       " 'Gender': 0.0,\n",
       " 'Scholarship holder': 0.0,\n",
       " 'Age at enrollment': 18.0,\n",
       " 'International': 0.0,\n",
       " 'Curricular units 1st sem (credited)': 0.0,\n",
       " 'Curricular units 1st sem (enrolled)': 6.0,\n",
       " 'Curricular units 1st sem (evaluations)': 7.0,\n",
       " 'Curricular units 1st sem (approved)': 6.0,\n",
       " 'Curricular units 1st sem (grade)': 13.0,\n",
       " 'Curricular units 1st sem (without evaluations)': 0.0,\n",
       " 'Curricular units 2nd sem (credited)': 0.0,\n",
       " 'Curricular units 2nd sem (enrolled)': 6.0,\n",
       " 'Curricular units 2nd sem (evaluations)': 6.0,\n",
       " 'Curricular units 2nd sem (approved)': 6.0,\n",
       " 'Curricular units 2nd sem (grade)': 13.666666666666666,\n",
       " 'Curricular units 2nd sem (without evaluations)': 0.0,\n",
       " 'Unemployment rate': 12.4,\n",
       " 'Inflation rate': 0.5,\n",
       " 'GDP': 1.79,\n",
       " 'Target': 1.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data = load_student_data()\n",
    "print('Number of examples:', len(student_data))\n",
    "print('An example:')\n",
    "student_data[100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_vals(data, f):\n",
    "    vals = [entry[f] for entry in data]\n",
    "    avg = sum(vals) / len(vals)\n",
    "    dev = [(entry[f] - avg)**2 for entry in data]\n",
    "    sd = (sum(dev) / len(vals))**0.5\n",
    "    return avg, sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard(v, std):\n",
    "    return [(v - std[0]) / std[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw(x):\n",
    "    return [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(v, entries):\n",
    "    '''\n",
    "    v -- value\n",
    "    entries -- possible values\n",
    "    '''\n",
    "    vec = len(entries) * [0]\n",
    "    vec[entries.index(v)] = 1\n",
    "    return vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    ('Marital status', one_hot),\n",
    "    ('Application mode', one_hot),\n",
    "    ('Application order', raw),\n",
    "    ('Course', one_hot),\n",
    "    ('Daytime/evening attendance\\t', raw),\n",
    "    ('Previous qualification', one_hot),\n",
    "    ('Previous qualification (grade)', standard),\n",
    "    ('Nacionality', one_hot),\n",
    "    (\"Mother's qualification\", one_hot),\n",
    "    (\"Father's qualification\", one_hot),\n",
    "    (\"Mother's occupation\", one_hot),\n",
    "    (\"Father's occupation\", one_hot),\n",
    "    ('Admission grade', standard),\n",
    "    ('Displaced', raw),\n",
    "    ('Educational special needs', raw),\n",
    "    ('Debtor', raw),\n",
    "    ('Tuition fees up to date', raw),\n",
    "    ('Gender', raw),\n",
    "    ('Scholarship holder', raw),\n",
    "    ('Age at enrollment', raw),\n",
    "    ('International', raw),\n",
    "    ('Curricular units 1st sem (credited)', raw),\n",
    "    ('Curricular units 1st sem (enrolled)', raw),\n",
    "    ('Curricular units 1st sem (evaluations)', raw),\n",
    "    ('Curricular units 1st sem (approved)', raw),\n",
    "    ('Curricular units 1st sem (grade)', raw),\n",
    "    ('Curricular units 1st sem (without evaluations)', raw),\n",
    "    ('Curricular units 2nd sem (credited)', raw),\n",
    "    ('Curricular units 2nd sem (enrolled)', raw),\n",
    "    ('Curricular units 2nd sem (evaluations)', raw),\n",
    "    ('Curricular units 2nd sem (approved)', raw),\n",
    "    ('Curricular units 2nd sem (grade)', raw),\n",
    "    ('Curricular units 2nd sem (without evaluations)', raw),\n",
    "    ('Unemployment rate', standard),\n",
    "    ('Inflation rate', standard),\n",
    "    ('GDP', standard),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, features, verbose=True):\n",
    "    features = [('Target', raw)] + features\n",
    "    std = {f : std_vals(data, f) \\\n",
    "           for (f,phi) in features if phi == standard}\n",
    "    entries = {f : list(set([entry[f] for entry in data])) \\\n",
    "               for (f, phi) in features if phi == one_hot} \n",
    "    if verbose: print('Mean and Std:', std)\n",
    "    if verbose: print('Entries in one_hot field:', entries)\n",
    "    \n",
    "    findex = 0\n",
    "    # Print the meaning of features\n",
    "    for (f, phi) in features[1:]: # skip 'Target'\n",
    "        if phi == standard:\n",
    "            if verbose: print(findex, f, 'std')\n",
    "            findex += 1\n",
    "        elif phi == one_hot:\n",
    "            for entry in entries[f]:\n",
    "                if verbose: print(findex, f, entry, 'one_hot')\n",
    "                findex += 1\n",
    "        else:\n",
    "            if verbose: print(findex, f, 'raw')\n",
    "            findex += 1\n",
    "\n",
    "    vals = []\n",
    "    for entry in data:\n",
    "        phis = []\n",
    "        for (f, phi) in features:\n",
    "            if phi == standard:\n",
    "                phis.extend(phi(entry[f], std[f]))\n",
    "            elif phi == one_hot:\n",
    "                phis.extend(phi(entry[f], entries[f]))\n",
    "            else:\n",
    "                phis.extend(phi(entry[f]))\n",
    "        vals.append(np.array([phis])) # phis of shape (1,D)\n",
    "    \n",
    "    data = np.vstack(vals)\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(data)\n",
    "    return data[:, 1:], data[:, 0:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data shape: (3630, 238)\n",
      "Labels shape: (3630, 1)\n"
     ]
    }
   ],
   "source": [
    "X, y = preprocess(student_data, features, verbose=False)\n",
    "print('\\nData shape:', X.shape)\n",
    "print('Labels shape:', y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(data, labels, test_pct=0.2, seed=None):\n",
    "    if seed and isinstance(seed, int):\n",
    "        np.random.seed(seed)\n",
    "    n, d = data.shape\n",
    "    idxs = np.random.permutation(n)\n",
    "    split_pt = int((1 - test_pct) * n)\n",
    "    train_idxs, test_idxs = idxs[:split_pt], idxs[split_pt:]\n",
    "    X_train, y_train = data[train_idxs, :], labels[train_idxs, :]\n",
    "    X_test, y_test = data[test_idxs, :], labels[test_idxs, :]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(data, labels, test_pct=0.2, seed=None):\n",
    "    if seed and isinstance(seed, int):\n",
    "        np.random.seed(seed)\n",
    "    unique_labels, label_counts = np.unique(labels, return_counts=True)\n",
    "    test_label_counts = (label_counts * test_pct).astype(int)\n",
    "    train_label_counts = label_counts - test_label_counts\n",
    "    train_idxs, test_idxs = [], []\n",
    "    for label, train_count, test_count in zip(unique_labels, train_label_counts, test_label_counts):\n",
    "        label_idxs = np.where(labels == label)[0] # return an array of indexes\n",
    "        permuted_idxs = np.random.permutation(label_idxs)\n",
    "        train_idxs.extend(permuted_idxs[:train_count])\n",
    "        test_idxs.extend(permuted_idxs[train_count:train_count+test_count])\n",
    "    X_train, y_train = data[train_idxs], labels[train_idxs]\n",
    "    X_test, y_test = data[test_idxs], labels[test_idxs]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train, X_test, y_test = random_split(X, y)\n",
    "X_train, y_train, X_test, y_test = stratified_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels:\n",
      "  -1.0 appears 1137 times - 39.14%\n",
      "  1.0 appears 1768 times - 60.86%\n",
      "Test labels:\n",
      "  -1.0 appears 284 times - 39.17%\n",
      "  1.0 appears 441 times - 60.83%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def value_counts(y):\n",
    "    vals, cnts = np.unique(y, return_counts=True)\n",
    "    probs = cnts / np.sum(cnts)\n",
    "    for value, count, prob in zip(vals, cnts, probs):\n",
    "        print(f\"  {value} appears {count} times - {prob*100:.2f}%\")\n",
    "    return vals, cnts, probs\n",
    "\n",
    "print('Train labels:')\n",
    "train_vals, train_cnts, train_probs = value_counts(y_train)\n",
    "print('Test labels:')\n",
    "test_vals, test_cnts, test_probs = value_counts(y_test)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "ax1.bar(train_vals, train_probs)\n",
    "ax1.set_title(\"Training set\")\n",
    "ax1.set_xlabel(\"Unique value\")\n",
    "ax1.set_ylabel(\"Probability\")\n",
    "\n",
    "ax2.bar(test_vals, test_probs)\n",
    "ax2.set_title(\"Testing set\")\n",
    "ax2.set_xlabel(\"Unique value\")\n",
    "ax2.set_ylabel(\"Probability\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "def accuracy(y_pred, y_true):\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "\n",
    "# Calculate precision\n",
    "def precision(y_pred, y_true):\n",
    "    class_labels = np.unique(y_true)  # Get unique class labels\n",
    "    precision_scores = []\n",
    "    for label in class_labels:\n",
    "        TP = np.sum(np.logical_and(y_pred == label, y_true == label))\n",
    "        FP = np.sum(np.logical_and(y_pred == label, y_true != label))\n",
    "        precision = TP / (TP + FP)\n",
    "        precision_scores.append(precision)\n",
    "    average_precision = np.mean(precision_scores)\n",
    "    return average_precision\n",
    "\n",
    "# Calculate recall\n",
    "def recall(y_pred, y_true):\n",
    "    class_labels = np.unique(y_true)  # Get unique class labels\n",
    "    recall_scores = []\n",
    "    for label in class_labels:\n",
    "        TP = np.sum(np.logical_and(y_pred == label, y_true == label))\n",
    "        FN = np.sum(np.logical_and(y_pred != label, y_true == label))\n",
    "        recall = TP / (TP + FN)\n",
    "        recall_scores.append(recall)\n",
    "    average_recall = np.mean(recall_scores)\n",
    "    return average_recall\n",
    "\n",
    "# Calculate F1 score\n",
    "def f1(y_pred, y_true):\n",
    "    class_labels = np.unique(y_true)  # Get unique class labels\n",
    "    f1_scores = []\n",
    "    for label in class_labels:\n",
    "        TP = np.sum(np.logical_and(y_pred == label, y_true == label))\n",
    "        FP = np.sum(np.logical_and(y_pred == label, y_true != label))\n",
    "        FN = np.sum(np.logical_and(y_pred != label, y_true == label))\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        f1_scores.append(f1)\n",
    "    average_f1 = np.mean(f1_scores)\n",
    "    return average_f1\n",
    "\n",
    "# Confusion matrix\n",
    "def confusion_matrix():\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree node class\n",
    "class DTNode:\n",
    "    N_THRESHOLD = 4 # don't split if node has fewer examples than this\n",
    "    H_THRESHOLD = .01 # don't split if node has entropy less than this\n",
    "    H_REDUCTION_THRESHOLD = .001 # don't split if entropy reduction is less than this\n",
    "    index = 0\n",
    "\n",
    "    def __init__(self, data=None, config=None):\n",
    "        self.config = config\n",
    "        if config != None:\n",
    "            self.N_THRESHOLD = config[0]\n",
    "            self.H_THRESHOLD = config[1]\n",
    "            self.H_REDUCTION_THRESHOLD = config[2]\n",
    "        \n",
    "        DTNode.index += 1\n",
    "        self.index = DTNode.index # node has unique number\n",
    "        self.data = data\n",
    "        self.prob = None\n",
    "        if data is not None:\n",
    "            self.n = float(data.shape[0]) # number of examples\n",
    "            self.indices = range(data.shape[1] - 1) # feature indices\n",
    "            self.set_h()\n",
    "\n",
    "        self.splits = {}\n",
    "\n",
    "        self.feat_id = None # feature index\n",
    "        self.thres = None # threshold\n",
    "        self.lchild = None # left child\n",
    "        self.rchild = None # right child\n",
    "        self.parent = None\n",
    "\n",
    "    # Create split on feature 'i' at value 'th'\n",
    "    def split(self, i, th):\n",
    "        self.feat_id = i\n",
    "        self.thres = th\n",
    "        self.lchild = DTNode(self.data[self.data[:, i] < th], self.config)\n",
    "        self.rchild = DTNode(self.data[self.data[:, i] >= th], self.config)\n",
    "        self.splits[i].remove(th)\n",
    "\n",
    "    # Evaluate candidate split by weighted average entropy\n",
    "    def split_eval(self, i, th):\n",
    "        lc = DTNode(self.data[self.data[:, i] < th], self.config)\n",
    "        rc = DTNode(self.data[self.data[:, i] >= th], self.config)\n",
    "        pl = lc.n / self.n\n",
    "        pr = 1.0 - pl\n",
    "        avgH = pl * lc.H + pr * rc.H\n",
    "        return avgH, lc, rc\n",
    "    \n",
    "    # Entropy of class labels in this node, assumes 1, -1\n",
    "    def set_h(self):\n",
    "        b = .001\n",
    "        npos = np.sum(self.data[:,-1] == 1) # count labels 1\n",
    "        p = (npos + b) / (self.n + b + b)\n",
    "        self.prob = p\n",
    "        self.H = -p * np.log(p) - (1-p) * np.log(1-p)\n",
    "\n",
    "    def build_tree(self):\n",
    "        if self.H < self.H_THRESHOLD or self.n <= self.N_THRESHOLD:\n",
    "            return\n",
    "        # Find the best split\n",
    "        (i, th, (h, lc, rc)) = argmax([(i, th, self.split_eval(i, th)) \\\n",
    "                                            for i in self.indices \\\n",
    "                                            for th in self.get_splits(i)],\n",
    "                                        lambda x : -x[2][0]) # x = (a, b, (h, c, d))\n",
    "        \n",
    "        if (self.H - h) < self.H_REDUCTION_THRESHOLD:\n",
    "            return\n",
    "        # Recurse\n",
    "        self.feat_id = i\n",
    "        self.thres = th\n",
    "        self.lchild = lc\n",
    "        self.rchild = rc\n",
    "        self.lchild.parent = self\n",
    "        self.rchild.parent = self\n",
    "        self.lchild.build_tree()\n",
    "        self.rchild.build_tree()\n",
    "    \n",
    "    # Sort examples and return middle points between every two consecutive sampes\n",
    "    def get_splits(self, i):\n",
    "        if i not in self.splits:\n",
    "            d = np.sort(np.unique(self.data[:,i]), axis=None)\n",
    "            d1 = d[:-1]\n",
    "            d2 = d[1:]\n",
    "            self.splits[i] = (d1 + d2) / 2.0\n",
    "        return self.splits[i]\n",
    "\n",
    "    # Classify a data point\n",
    "    def classify(self, x):\n",
    "        if self.feat_id == None: # leaf node\n",
    "            return self.prob\n",
    "        elif x[self.feat_id] < self.thres:\n",
    "            return self.lchild.classify(x) # go to left child\n",
    "        else:\n",
    "            return self.rchild.classify(x) # go to right child\n",
    "        \n",
    "    def display(self, depth=0, max_depth=3):\n",
    "        if depth > max_depth:\n",
    "            print(depth*'  ', 'Depth >', max_depth)\n",
    "        if self.feat_id is None:\n",
    "            print(depth*'  ', '=>', '%.2f'%self.prob, '[ n=', self.n, ']')\n",
    "            return\n",
    "        print(depth*'  ', 'Ft.', self.feat_id, '<', self.thres, '[ n=', self.n, ']')\n",
    "        self.lchild.display(depth+1, max_depth)\n",
    "        self.rchild.display(depth+1, max_depth)\n",
    "\n",
    "def argmax(l, f):\n",
    "    \"\"\"\n",
    "    Return the element in list l that gives highest value on f\n",
    "\n",
    "    @param l: C{List} of items\n",
    "    @param f: C{Procedure} that maps an item into a numeric score\n",
    "    @returns: the element of C{l} that has the highest score\n",
    "    \"\"\"\n",
    "    vals = [f(x) for x in l]\n",
    "    return l[vals.index(max(vals))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def fit(self, X, Y, config=None):\n",
    "        D = np.hstack([X,Y])\n",
    "        self.root = DTNode(D, config)\n",
    "        self.root.build_tree()\n",
    "    def predict(self, X):\n",
    "        pred = np.array([np.apply_along_axis(self.root.classify, 1, X)]).T - 0.5\n",
    "        pred[pred >= 0] = 1\n",
    "        pred[pred < 0] = -1\n",
    "        return pred\n",
    "    def display(self, depth=0, max_depth=3):\n",
    "        self.root.display(depth, max_depth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bagging:\n",
    "    def __init__(self, num_trees=5):\n",
    "        self.ntrees = num_trees\n",
    "        self.trees = []\n",
    "    def fit(self, X, Y, config=None):\n",
    "        for i in range(self.ntrees):\n",
    "            # perms = np.random.permutation(len(X))\n",
    "            idxs = np.random.choice(len(X), size=len(X), replace=True)\n",
    "            X_train = X[idxs, :]\n",
    "            Y_train = Y[idxs, :]\n",
    "            dt = DecisionTree()\n",
    "            dt.fit(X_train, Y_train, config)\n",
    "            self.trees.append(dt)\n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        if len(self.trees) == 0: return None\n",
    "        for dt in self.trees:\n",
    "            pred = dt.predict(X)\n",
    "            preds.append(pred)\n",
    "        preds = np.hstack(preds)\n",
    "        return np.sign(preds.mean(axis=1, keepdims=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, num_trees=5, num_features=None):\n",
    "        self.ntrees = num_trees\n",
    "        self.nfeats = num_features\n",
    "        self.trees = []\n",
    "        self.feats = []\n",
    "    \n",
    "    def fit(self, X, Y, config=None):\n",
    "        for i in range(self.ntrees):\n",
    "            idxs = np.random.choice(len(X), size=len(X), replace=True)\n",
    "            if self.nfeats is not None:\n",
    "                features = np.random.choice(X.shape[1], size=self.nfeats, replace=False)\n",
    "                X_train = X[idxs][:, features]\n",
    "                self.feats.append(features)\n",
    "            else:\n",
    "                X_train = X[idxs]\n",
    "            Y_train = Y[idxs]\n",
    "            dt = DecisionTree()\n",
    "            dt.fit(X_train, Y_train, config)\n",
    "            self.trees.append(dt)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        if len(self.trees) == 0:\n",
    "            return None\n",
    "        for i in range(len(self.trees)):\n",
    "            dt = self.trees[i]\n",
    "            if self.nfeats is not None:\n",
    "                features = self.feats[i]\n",
    "                X_test = X[:, features]\n",
    "            else:\n",
    "                X_test = X\n",
    "                \n",
    "            pred = dt.predict(X_test)\n",
    "            preds.append(pred)\n",
    "        preds = np.hstack(preds)\n",
    "        return np.sign(np.mean(preds, axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_class, X_train, Y_train, X_test, Y_test, max_depth=5, verbose=True, config=None, args=None):\n",
    "    if args:\n",
    "        model = model_class(*args)\n",
    "    else:\n",
    "        model = model_class()\n",
    "    model.fit(X_train, Y_train, config)\n",
    "    pred_test = model.predict(X_test)\n",
    "    acc_s = accuracy(pred_test, Y_test)\n",
    "    prec_s = precision(pred_test, Y_test)\n",
    "    rec_s = recall(pred_test, Y_test)\n",
    "    f1_s = f1(pred_test, Y_test)\n",
    "    if verbose:\n",
    "        print(f'  Accuracy  : {acc_s:.5f}')\n",
    "        print(f'  Precision : {prec_s:.5f}')\n",
    "        print(f'  Recall    : {rec_s:.5f}')\n",
    "        print(f'  F1        : {f1_s:.5f}')\n",
    "        if isinstance(model, DecisionTree): \n",
    "            model.display(max_depth=max_depth)\n",
    "    return acc_s, prec_s, rec_s, f1_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1\n",
      "  Accuracy  : 0.90706\n",
      "  Precision : 0.91229\n",
      "  Recall    : 0.89006\n",
      "  F1        : 0.89890\n",
      "Round: 2\n",
      "  Accuracy  : 0.88985\n",
      "  Precision : 0.89261\n",
      "  Recall    : 0.87962\n",
      "  F1        : 0.88468\n",
      "Round: 3\n",
      "  Accuracy  : 0.91738\n",
      "  Precision : 0.91262\n",
      "  Recall    : 0.90485\n",
      "  F1        : 0.90850\n",
      "Round: 4\n",
      "  Accuracy  : 0.89845\n",
      "  Precision : 0.90238\n",
      "  Recall    : 0.88980\n",
      "  F1        : 0.89453\n",
      "Round: 5\n",
      "  Accuracy  : 0.89329\n",
      "  Precision : 0.89528\n",
      "  Recall    : 0.87891\n",
      "  F1        : 0.88556\n",
      "CROSS VALIDATION RESULTS:\n",
      "- Accuracy  : 0.90120\n",
      "- Precision : 0.90303\n",
      "- Recall    : 0.88865\n",
      "- F1        : 0.89443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9012048192771085, 0.903033484095722, 0.8886483345696078, 0.8944344881789963)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_validate(data, labels, k=10, model='DecisionTree', verbose=True, config=None, args=None):\n",
    "    if model == 'Bagging':\n",
    "        model_class = Bagging\n",
    "    elif model == 'RandomForest':\n",
    "        model_class = RandomForest\n",
    "    else:\n",
    "        model_class = DecisionTree\n",
    "    indices = np.random.permutation(data.shape[0])\n",
    "    X = data[indices,:]\n",
    "    Y = labels[indices,:]\n",
    "    s_data = np.array_split(X, k, axis=0)\n",
    "    s_labels = np.array_split(Y, k, axis=0)\n",
    "    acc_s = 0.\n",
    "    prec_s = 0.\n",
    "    rec_s = 0.\n",
    "    f1_s = 0.\n",
    "    for i in range(k):\n",
    "        X_train = np.concatenate(s_data[:i] + s_data[i+1:], axis=0)\n",
    "        Y_train = np.concatenate(s_labels[:i] + s_labels[i+1:], axis=0)\n",
    "        X_test = np.array(s_data[i])\n",
    "        Y_test = np.array(s_labels[i])\n",
    "        if verbose == \"first_tree\":\n",
    "            if i == 0:\n",
    "                acc, prec, rec, f1 = evaluate(model_class, X_train, Y_train, X_test, Y_test, verbose=True, config=config, args=args)\n",
    "            else:\n",
    "                acc, prec, rec, f1 = evaluate(model_class, X_train, Y_train, X_test, Y_test, verbose=False, config=config, args=args)\n",
    "        elif verbose == True:\n",
    "            print('Round',i+1)\n",
    "            acc, prec, rec, f1 = evaluate(model_class, X_train, Y_train, X_test, Y_test, verbose=True, config=config, args=args)\n",
    "        else:\n",
    "            acc, prec, rec, f1 = evaluate(model_class, X_train, Y_train, X_test, Y_test, verbose=False, config=config, args=args)\n",
    "        acc_s += acc\n",
    "        prec_s += prec\n",
    "        rec_s += rec\n",
    "        f1_s += f1\n",
    "    print('\\nCROSS VALIDATION RESULTS:')\n",
    "    print(f'- Avg. Accuracy  : {acc_s/k:.5f}')\n",
    "    print(f'- Avg. Precision : {prec_s/k:.5f}')\n",
    "    print(f'- Avg. Recall    : {rec_s/k:.5f}')\n",
    "    print(f'- Avg. F1        : {f1_s/k:.5f}')\n",
    "    return acc_s/k, prec_s/k, rec_s/k, f1_s/k\n",
    "\n",
    "\n",
    "# cross_validate(X_train, y_train, model='RandomForest', k=5, verbose=True, args=[5, 150])\n",
    "cross_validate(X_train, y_train, model='Bagging', k=5, verbose=True, args=[7])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO (Viet)\n",
    "1. Find the best values \n",
    "    of N_THRESHOLD, H_THRESHOLD, H_REDUCTION_THRESHOLD for Decision tree\n",
    "2. Find the best values\n",
    "    of 'num_trees' and 'num_features' for Random forest\n",
    "3. Find the best values\n",
    "    of 'num_trees' for Bagging\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO\n",
    "- Function to turn user inputs into vector ready to be put into 'predit' function (shape (1, 238)) (Lam)\n",
    "- Plot various values of hyperparams for dtree, bagging, rforest -> find optimal values & Confusion matrix (Loc)\n",
    "- Fix errors for functions to save and load models (by yaml) (Dai)\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warnings:** Don't run this part until very end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(RandomForest, X_train, y_train, X_test, y_test, args=[5, 150])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForest(num_trees=5, num_features=150)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Enrolled: 1.0, Dropout: -1.0)\n",
      "- Prediction : -1.0\n",
      "- Actual     : -1.0\n"
     ]
    }
   ],
   "source": [
    "id = 123\n",
    "\n",
    "# load model\n",
    "\n",
    "print('(Graduated: 1.0, Dropout: -1.0)')\n",
    "print('- Prediction :', rf_clf.predict(X_test[id,:].reshape(1,-1))[0][0])\n",
    "print('- Actual     :', y_test[id][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
